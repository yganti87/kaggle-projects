{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on Wine Quality Dataset\n",
    "\n",
    "This notebook demonstrates a simple linear regression model on the Wine Quality dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df = pd.read_csv(url, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# df.drop('quality', axis=1) removes the 'quality' column from the dataframe.\n",
    "# 'quality' is the target variable we want to predict, so we exclude it from the features (X).\n",
    "# axis=1 specifies that we are dropping a column (not a row).\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "# Split the data into training and test sets\n",
    "# train_test_split() randomly splits the data into training and test sets\n",
    "# X_train and y_train will be used to train the model\n",
    "# X_test and y_test will be used to evaluate the model's performance\n",
    "# test_size=0.2 means 20% of the data will be used for testing\n",
    "# random_state=42 ensures reproducibility of the random split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here to visualize the data\n",
    "# Distribution of wine quality scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['quality'], bins=7, kde=True)\n",
    "plt.title('Distribution of Wine Quality Scores')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "# Calculate correlations between all numeric columns using df.corr()\n",
    "# df.corr() computes the pairwise correlation of columns using Pearson correlation coefficient\n",
    "# The correlation coefficient ranges from -1 to 1:\n",
    "#   1: Perfect positive correlation\n",
    "#   0: No correlation\n",
    "#   -1: Perfect negative correlation\n",
    "# The diagonal is always 1 since each feature perfectly correlates with itself\n",
    "# The Pearson correlation coefficient measures the strength and direction of the linear relationship\n",
    "# between two variables. For each pair of features, it shows:\n",
    "# - How strongly they are related (magnitude from 0 to 1)\n",
    "# - Whether the relationship is positive or negative (sign)\n",
    "# - Values closer to 1 indicate strong positive correlation (as one increases, the other increases)\n",
    "# - Values closer to -1 indicate strong negative correlation (as one increases, the other decreases) \n",
    "# - Values close to 0 indicate little to no linear relationship\n",
    "#\n",
    "# This helps identify:\n",
    "# 1. Which features might be most important for predicting wine quality\n",
    "# 2. Potential multicollinearity (highly correlated features that could affect model performance)\n",
    "# 3. Redundant features that could potentially be removed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Create and train a Linear Regression model\n",
    "# LinearRegression() creates an instance of the linear regression model\n",
    "# This model will learn the relationship between the wine features (X_train) \n",
    "# and the quality scores (y_train)\n",
    "# The model finds the best-fit line by minimizing the sum of squared residuals\n",
    "# It learns coefficients (weights) for each feature and an intercept term\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "# Use the trained model to predict quality scores for the test set\n",
    "# The model will use the learned coefficients to predict quality scores\n",
    "# for each wine in the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual vs predicted values for a sample of wines\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Quality': y_test,\n",
    "    'Predicted Quality': y_pred,\n",
    "    'Difference': y_test - y_pred\n",
    "})\n",
    "\n",
    "# Display first 10 rows of the comparison\n",
    "print(\"Sample Comparison of Actual vs Predicted Wine Quality:\")\n",
    "print(comparison_df.head(10).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot comparing actual vs predicted quality for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(range(len(y_pred)), y_pred, alpha=0.6, label='Predicted Quality', marker='o')\n",
    "plt.scatter(range(len(y_test)), y_test, alpha=0.6, label='Actual Quality', marker='^')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Wine Quality')\n",
    "plt.title('Actual vs Predicted Wine Quality per Sample')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance with multiple plots\n",
    "# 1. Scatter plot of actual vs predicted values with perfect prediction line\n",
    "# 2. Distribution of residuals to check for normality \n",
    "# 3. Residuals vs predicted values to check for homoscedasticity\n",
    "# 4. Feature importance plot based on model coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Wine Quality')\n",
    "plt.ylabel('Predicted Wine Quality')\n",
    "plt.title('Actual vs Predicted Wine Quality')\n",
    "\n",
    "# Add text box with metrics\n",
    "plt.text(0.05, 0.95, f'MSE: {mse:.2f}\\nRÂ²: {r2:.2f}', \n",
    "         transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Wine Quality')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "# Plot histogram of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Zero Residual')\n",
    "plt.xlabel('Residual Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': abs(model.coef_)\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance Based on Model Coefficients')\n",
    "plt.show()\n",
    "# Plot prediction error over index\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), abs(residuals), alpha=0.7)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Prediction Error')\n",
    "plt.title('Prediction Error Over Samples')\n",
    "plt.axhline(y=abs(residuals).mean(), color='r', linestyle='--', \n",
    "           label=f'Mean Error: {abs(residuals).mean():.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
